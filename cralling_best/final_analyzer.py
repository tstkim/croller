"""
ìƒí’ˆ í˜ì´ì§€ ì§ì ‘ ë¶„ì„ ë° ì •í™•í•œ ì„ íƒì íƒì§€ (3ê°œ ìƒí’ˆ ë³´ì¥)
"""
import asyncio
import traceback
from playwright.async_api import async_playwright
from site_config import *
from login_manager import LoginManager
import json
import re
from datetime import datetime


class FinalAnalyzer:
    def __init__(self):
        self.login_manager = LoginManager()
        self.selectors = {}
        self.test_data = []
    
    async def _detect_product_link_selector(self, page):
        """ìƒí’ˆ ê°¤ëŸ¬ë¦¬ì—ì„œ ìƒí’ˆ ë§í¬ a íƒœê·¸ì˜ ì„ íƒìë¥¼ ë™ì ìœ¼ë¡œ íƒì§€"""
        # 1. ëª¨ë“  a íƒœê·¸ ìˆ˜ì§‘
        handles = await page.query_selector_all('a')
        selector_count = {}
        for handle in handles:
            href = await handle.get_attribute('href')
            if href and '/goods/view' in href:
                # CSS selector ìƒì„±
                selector = await page.evaluate('(el) => el.outerHTML', handle)
                # id, class, tag ê¸°ë°˜ selector ì¶”ì¶œ
                id_attr = await handle.get_attribute('id')
                class_attr = await handle.get_attribute('class')
                if id_attr:
                    sel = f"a#{id_attr}"
                elif class_attr:
                    sel = f"a.{'.'.join(class_attr.split())}"
                else:
                    sel = 'a[href*="/goods/view"]'
                selector_count[sel] = selector_count.get(sel, 0) + 1
        # ê°€ì¥ ë§ì´ ë“±ì¥í•˜ëŠ” selector ë°˜í™˜
        if selector_count:
            return max(selector_count, key=selector_count.get)
        return 'a[href*="/goods/view"]'

    async def run(self):
        """ë©”ì¸ ì‹¤í–‰"""
        print("ğŸ¯ ìµœì¢… ìƒí’ˆ ë¶„ì„ê¸° ì‹œì‘...")
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=False)
            context = await browser.new_context(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36")
            page = await context.new_page()
            try:
                # ë¡œê·¸ì¸ (ë™ì¼ page/contextì—ì„œ ì§„í–‰)
                if LOGIN_REQUIRED:
                    await self.login_manager.auto_login(page, MAIN_URL, USERNAME, PASSWORD)
                    await asyncio.sleep(1)  # ì„¸ì…˜ ì ìš© ëŒ€ê¸°
                    print("[ë¡œê·¸] ë¡œê·¸ì¸ í›„ ì¿ í‚¤:", await context.cookies())
                    await page.reload()  # ì„¸ì…˜ ê°•ì œ ë™ê¸°í™”
                print(f"[ë¡œê·¸] ë¡œê·¸ì¸ í›„ í˜„ì¬ URL: {page.url}")
                # ë¡œê·¸ì¸ í›„ ê³§ë°”ë¡œ ê°¤ëŸ¬ë¦¬ í˜ì´ì§€ë¡œ ì´ë™
                await page.goto(GALLERY_URL, wait_until="domcontentloaded", timeout=30000, referer=MAIN_URL)
                await page.wait_for_load_state("networkidle", timeout=15000)
                print(f"[ë¡œê·¸] ê°¤ëŸ¬ë¦¬ ì´ë™ í›„ í˜„ì¬ URL: {page.url}")
                if not page.url.startswith(GALLERY_URL.split('?')[0]):
                    print(f"[ê²½ê³ ] ê°¤ëŸ¬ë¦¬ í˜ì´ì§€ë¡œ ì •ìƒ ì´ë™í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í˜„ì¬ URL: {page.url}")
                # ìƒí’ˆ ë§í¬ ì„ íƒì ë™ì  íƒì§€
                product_link_selector = await self._detect_product_link_selector(page)
                self.selectors['ìƒí’ˆë§í¬'] = product_link_selector
                # í…ŒìŠ¤íŠ¸ ë§í¬ ìˆ˜ì§‘
                test_links = await self._get_test_links(page, product_link_selector)
                print(f"âœ… ìˆ˜ì§‘ëœ í…ŒìŠ¤íŠ¸ ë§í¬: {len(test_links)}ê°œ")
                if test_links:
                    # ì„ íƒì íƒì§€
                    print(f"\nğŸ” ì„ íƒì íƒì§€...")
                    await self._analyze_selectors(page, test_links[0])
                    # 3ê°œ ìƒí’ˆ ê°•ì œ ì²˜ë¦¬
                    await self._extract_three_products(page, test_links)
                # ê²°ê³¼ ì €ì¥
                self._save_result()
            finally:
                await browser.close()
    
    async def _get_test_links(self, page, product_link_selector=None):
        """í…ŒìŠ¤íŠ¸ ë§í¬ ìˆ˜ì§‘ (ìƒí’ˆ ë§í¬ ì„ íƒì ì‚¬ìš©)"""
        try:
            await page.goto(GALLERY_URL, timeout=30000)
            await page.wait_for_load_state("networkidle", timeout=15000)
            selector = product_link_selector or 'a[href*="/goods/view"]'
            links = await page.evaluate(f'''
                () => {{
                    const links = Array.from(document.querySelectorAll('{selector}'));
                    return links.map(link => link.href).filter(href => href);
                }}
            ''')
            unique_links = list(set(links))[:10]
            return unique_links
            
        except Exception as e:
            print(f"âŒ ë§í¬ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return [SAMPLE_PRODUCT_URL]
    
    async def _analyze_selectors(self, page, url):
        """ì„ íƒì ë¶„ì„ (ìƒí’ˆë§í¬ í¬í•¨)"""
        try:
            await page.goto(url, timeout=30000)
            await page.wait_for_load_state("networkidle", timeout=15000)
            
            # ê¸°ì¡´ ì„±ê³µí•œ ì„ íƒìë“¤ ì‚¬ìš©
            self.selectors.update({
                'ìƒí’ˆëª…': '.name',
                'ê°€ê²©': '.org_price', 
                'ì„ íƒì˜µì…˜': 'select:nth-of-type(2)',
                'ì¸ë„¤ì¼': '.viewImgWrap img',
                'ìƒì„¸í˜ì´ì§€': '.goods_description img'
            })
            
            print("ğŸ“‹ ì„ íƒì ì„¤ì • ì™„ë£Œ:")
            for key, value in self.selectors.items():
                print(f"   {key}: {value}")
                
        except Exception as e:
            print(f"âŒ ì„ íƒì ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    async def _extract_three_products(self, page, test_links):
        """3ê°œ ìƒí’ˆ ê°•ì œ ì¶”ì¶œ"""
        print(f"\nğŸ“Š 3ê°œ ìƒí’ˆ ê°•ì œ ì¶”ì¶œ ì‹œì‘...")
        
        successful_count = 0
        max_attempts = min(len(test_links), 10)
        
        for i in range(max_attempts):
            if successful_count >= 3:
                print(f"ğŸ‰ ëª©í‘œ ë‹¬ì„±! 3ê°œ ìƒí’ˆ ì¶”ì¶œ ì™„ë£Œ")
                break
                
            link = test_links[i]
            print(f"\n{'='*50}")
            print(f"ğŸ“¦ ìƒí’ˆ {i+1} ì²˜ë¦¬ ì¤‘... (ì„±ê³µ: {successful_count}/3)")
            print(f"ğŸ”— {link}")
            
            try:
                data = await self._extract_single_product(page, link)
                
                if data and data.get('ìƒí’ˆëª…', '').strip():
                    self.test_data.append(data)
                    successful_count += 1
                    
                    print(f"âœ… ìƒí’ˆ {i+1} ì„±ê³µ! ({successful_count}/3)")
                    print(f"   ğŸ“ ìƒí’ˆëª…: {data.get('ìƒí’ˆëª…', '')[:50]}...")
                    print(f"   ğŸ’° ê°€ê²©: {data.get('ê°€ê²©', 'N/A')}")
                    print(f"   âš™ï¸ ì˜µì…˜: {len(data.get('ì„ íƒì˜µì…˜', []))}ê°œ")
                    print(f"   ğŸ–¼ï¸ ì¸ë„¤ì¼: {'âœ…' if data.get('ì¸ë„¤ì¼') else 'âŒ'}")
                    print(f"   ğŸ“¸ ìƒì„¸ì´ë¯¸ì§€: {len(data.get('ìƒì„¸í˜ì´ì§€', []))}ê°œ")
                else:
                    print(f"âŒ ìƒí’ˆ {i+1} ì‹¤íŒ¨: ë°ì´í„° ë¶€ì¡±")
                    
            except Exception as e:
                print(f"âŒ ìƒí’ˆ {i+1} ì˜¤ë¥˜: {str(e)[:100]}")
            
            # ì„œë²„ ë¶€í•˜ ë°©ì§€
            if i < max_attempts - 1:
                await asyncio.sleep(1)
        
        print(f"\nğŸ ì¶”ì¶œ ì™„ë£Œ: {successful_count}ê°œ ì„±ê³µ")
    
    async def _extract_single_product(self, page, url):
        """ë‹¨ì¼ ìƒí’ˆ ë°ì´í„° ì¶”ì¶œ"""
        try:
            await page.goto(url, timeout=30000)
            await page.wait_for_load_state("networkidle", timeout=15000)
            
            data = {'url': url}
            
            # ìƒí’ˆëª…
            if self.selectors.get('ìƒí’ˆëª…'):
                try:
                    element = await page.query_selector(self.selectors['ìƒí’ˆëª…'])
                    if element:
                        data['ìƒí’ˆëª…'] = (await element.text_content()).strip()
                    else:
                        data['ìƒí’ˆëª…'] = None
                except:
                    data['ìƒí’ˆëª…'] = None
            else:
                data['ìƒí’ˆëª…'] = None
            
            # ê°€ê²© (ì •í™•í•œ ì¶”ì¶œ)
            if self.selectors.get('ê°€ê²©'):
                try:
                    element = await page.query_selector(self.selectors['ê°€ê²©'])
                    if element:
                        price_text = (await element.text_content()).strip()
                        # ì •í™•í•œ ìˆ«ì ì¶”ì¶œ
                        price_match = re.search(r'(\d{1,3}(?:,\d{3})*)', price_text)
                        if price_match:
                            data['ê°€ê²©'] = price_match.group(1) + 'ì›'
                        else:
                            # ë°±ì—…: ê°€ì¥ ê¸´ ìˆ«ì ì°¾ê¸°
                            numbers = re.findall(r'\d+', price_text.replace(',', ''))
                            if numbers:
                                longest_num = max(numbers, key=len)
                                if len(longest_num) >= 3:
                                    formatted_price = '{:,}'.format(int(longest_num))
                                    data['ê°€ê²©'] = formatted_price + 'ì›'
                                else:
                                    data['ê°€ê²©'] = price_text
                            else:
                                data['ê°€ê²©'] = price_text
                    else:
                        data['ê°€ê²©'] = None
                except:
                    data['ê°€ê²©'] = None
            else:
                data['ê°€ê²©'] = None
            
            # ì„ íƒì˜µì…˜
            if self.selectors.get('ì„ íƒì˜µì…˜'):
                try:
                    options = await page.query_selector_all(f"{self.selectors['ì„ íƒì˜µì…˜']} option")
                    option_list = []
                    for option in options:
                        text = (await option.text_content()).strip()
                        if text and text not in ['ì„ íƒ', '-- ì„ íƒ --', 'ì˜µì…˜ì„ íƒ', 'ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”']:
                            option_list.append(text)
                    data['ì„ íƒì˜µì…˜'] = option_list
                except:
                    data['ì„ íƒì˜µì…˜'] = []
            else:
                data['ì„ íƒì˜µì…˜'] = []
            
            # ì¸ë„¤ì¼
            if self.selectors.get('ì¸ë„¤ì¼'):
                try:
                    element = await page.query_selector(self.selectors['ì¸ë„¤ì¼'])
                    if element:
                        src = await element.get_attribute('src')
                        data_src = await element.get_attribute('data-src')
                        data_original = await element.get_attribute('data-original')
                        data['ì¸ë„¤ì¼'] = data_original or data_src or src
                    else:
                        data['ì¸ë„¤ì¼'] = None
                except:
                    data['ì¸ë„¤ì¼'] = None
            else:
                data['ì¸ë„¤ì¼'] = None
            
            # ìƒì„¸í˜ì´ì§€ ì´ë¯¸ì§€ (í•„í„°ë§ ì ìš©)
            if self.selectors.get('ìƒì„¸í˜ì´ì§€'):
                try:
                    images = await page.query_selector_all(self.selectors['ìƒì„¸í˜ì´ì§€'])
                    detail_images = []
                    for img in images:
                        src = await img.get_attribute('src')
                        data_src = await img.get_attribute('data-src')
                        data_original = await img.get_attribute('data-original')
                        best_url = data_original or data_src or src
                        
                        if best_url and self._is_valid_detail_image(best_url) and best_url not in detail_images:
                            detail_images.append(best_url)
                    
                    data['ìƒì„¸í˜ì´ì§€'] = detail_images[:10]
                except:
                    data['ìƒì„¸í˜ì´ì§€'] = []
            else:
                data['ìƒì„¸í˜ì´ì§€'] = []
            
            return data
            
        except Exception as e:
            print(f"âŒ ìƒí’ˆ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _is_valid_detail_image(self, url):
        """ìœ íš¨í•œ ìƒì„¸ ì´ë¯¸ì§€ì¸ì§€ íŒë‹¨"""
        if not url:
            return False
        
        url_lower = url.lower()
        
        # ì œì™¸í•  íŒ¨í„´ë“¤
        exclude_patterns = [
            'logo', 'icon', 'btn', 'menu', 'nav', 
            'design', 'ui', 'arrow', 'quick', 'zzim'
        ]
        
        for pattern in exclude_patterns:
            if pattern in url_lower:
                return False
        
        # í¬í•¨ë˜ì–´ì•¼ í•  íŒ¨í„´ë“¤
        include_patterns = ['editor', 'goods', 'product', 'data']
        for pattern in include_patterns:
            if pattern in url_lower:
                return True
        
        return False
    
    def _save_result(self):
        """ê²°ê³¼ ì €ì¥"""
        result = {
            'ì„ íƒì': self.selectors,
            'ì¶”ì¶œë°ì´í„°': self.test_data,
            'ìƒì„±ì¼ì‹œ': datetime.now().isoformat()
        }
        
        filename = f"perfect_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {filename}")
        print("\n" + "="*70)
        print("ğŸ¯ ìµœì¢… ê²°ê³¼:")
        print(f"   ğŸ“ ìƒí’ˆëª…: {self.selectors.get('ìƒí’ˆëª…', 'âŒ')}")
        print(f"   ğŸ’° ê°€ê²©: {self.selectors.get('ê°€ê²©', 'âŒ')}")
        print(f"   âš™ï¸ ì„ íƒì˜µì…˜: {self.selectors.get('ì„ íƒì˜µì…˜', 'âŒ')}")
        print(f"   ğŸ–¼ï¸ ì¸ë„¤ì¼: {self.selectors.get('ì¸ë„¤ì¼', 'âŒ')}")
        print(f"   ğŸ“¸ ìƒì„¸í˜ì´ì§€: {self.selectors.get('ìƒì„¸í˜ì´ì§€', 'âŒ')}")
        print(f"   ğŸ“Š ì¶”ì¶œëœ ìƒí’ˆ: {len(self.test_data)}ê°œ")


if __name__ == "__main__":
    analyzer = FinalAnalyzer()
    asyncio.run(analyzer.run())
    print("\nğŸ ì¶”ì¶œ ì™„ë£Œ! ìë™ ì¢…ë£Œë©ë‹ˆë‹¤.")
